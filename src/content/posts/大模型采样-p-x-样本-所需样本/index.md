---
title: "大模型采样：p (x) 样本 ≠ 所需样本"
tags: ["math"]
createdAt: "2025-10-27"
origin: "https://zhuanlan.zhihu.com/p/1966131267222366117"
excerpt: "最近采样的工作百花齐放，我在阅读文章的时候，意识到一个非常非常细微的区别： 从 [公式] 采样出的样本并不一定对应着你所需要的样本。 举一个最简单的例子，对于 高斯分布 [公式] 而言，你所期望的样本可能是 [公式] ，但是采样器却有不为零的概率采样到一些尾部数据。又或者你期望的样本其实是 [公式]..."
---

最近采样的工作百花齐放，我在阅读文章的时候，意识到一个非常非常细微的区别：

从 $p(x)$ 采样出的样本并不一定对应着你所需要的样本。

举一个最简单的例子，对于 高斯分布 $N(\mu, \sigma)$ 而言，你所期望的样本可能是 $\mu$ ，但是采样器却有不为零的概率采样到一些尾部数据。又或者你期望的样本其实是 $\mu + 3\sigma$ , 而采样器在大多数时候并不会涉及到这个区域。换句话说，你所期望的样本虽然被 $p(x)$ **覆盖** 了，但是你并没有办法强制采样器生成该样本。

聪明的读者很容易发现，我们需要一个“标准”来说明我们到底期望什么样的样本；以及这个分布 $p(x)$ 到底在怎么近似我们的样本（其实这两件事好像是同一件事）。比如说这个模型假设数据是真实样本+高斯噪声，那么真实样本“理应”是 $p(x)$ 的均值；我们有一个很简单的办法去获取真实想要的样本：采样N次，求平均。换句话说，我们所需的样本应该是模型设计阶段就已经想好的，以至于生成阶段可以通过某种方式求出它来。

如果我们把目光放到大语言模型上来看：由于大模型训练的目标是最大化似然，所以看上去，最天经地义的生成方式无疑是搜索整个概率图；但这样计算成本就爆炸了。一个近似是 beam search , 但是：

[LLM Decode不需要Beam Search——理解LLM输出的序列空间【2024.7】](https://zhuanlan.zhihu.com/p/707076469)

直观上来说，beam search会很受序列长度影响，越长的序列天然乘起来的概率更低。这里再post一个传统 NLP 对于beam search的讨论的汇总贴，事情比我们想象得更加复杂：

[你一直在用的Beam Search，是否真的有效？](https://link.zhihu.com/?target=https%3A//blog.csdn.net/qq_27590277/article/details/110413117)

无论如何，一切事实似乎都在说明， $p(x)$ 并非一个好指标。从另一个角度来说，采样N条回复，然后做一个“平均”的最终效果并不好。

为什么会出现这种情况？

让我们换个视角。首先，为了便于说明，我们约定两个空间：

1. token空间 。这个空间就是通常意义上的 token序列。可以进行字符串抽取，匹配，裁剪等等。
2. 回答空间 。这是一个抽象空间，相当于语义空间。我们对它什么也不知道。这个空间上只有严格相等，没有其他算子定义。

假设输入一个问题 $Q$ ，它有且仅有一个正确回答 $R$ . 我们记模型的生成为 $G$ , 同时约定算子 $\text{Extract}$ ，该算子可以从给定生成中截取其针对 $Q$ 的回复； 约定算子 $\text{Norm}$ ，该算子将 **token 空间** 的回复转换成 **回答空间** 的回复 。那么：

$P(\text{success}) = P(\text{R}=\text{Norm[Extract}(G)]\mid Q)$

$R= \text{Norm}[\text{Extract}(G)]$ 和 似然 $\prod p(x_i\mid x_0\cdots x_{i-1})$ **基本上没什么关系** 。完全可以构造这样一种生成情况，即大模型在输出 $R$ 之前输出了一段很长很长的序列，导致其累积概率非常低。（猴子打印机.jpg）

> 正确答案的似然是否比错误答案更高？值得验证，但是怎么设计输入，很模糊。

不过，如果LLM确实理解了语义空间，那么对 LLM采样N次，语义上出现最频繁的句子就应该是回复，这相当于 $\arg \max p(s)$ ， $p(s)$ 表示语义空间分布。如果语义和token是单射（例如选择题），那么这就是 Majority采样 。

这种思想进一步推广，可以训练一个 奖励模型 评价输出的质量。不过我对此持怀疑态度，因为语义空间应该是没有全序关系的，例如 2+2=？ 的输出，输出4和5确实可以比较，但是5和6就没法比较。根本不可能训练一个奖励模型去评价5和6的区别。

一个看上去合理的想法是 利用 $\iff$ 算子。生成N条回复，然后再两两判断是否等价，选择最大的等价类。这要求 $O(N^2)$ 次判断，计算开销非常大，而且判断似乎也只能依赖于LLM。

> 之前我一直被一个问题卡住，就是闲聊之类的场景，没法定义等价。现在我想明白了，不能等价那就是N个等价类随机抽样呗，这说明问题本身就很开放。Not a problem.

可以说，关键在于检查LLM输出的token序列在对应的语义空间上的位置。究其根本，我们将LLM视作一个语义空间概率模型的代理模型；而由于我们不知道token到语义的转换，只能转而诉诸频率来求最大值。

> 修修理理半天，感觉还是说不团圆。权当抛砖引玉，起到一个促进大家讨论的作用也不赖。